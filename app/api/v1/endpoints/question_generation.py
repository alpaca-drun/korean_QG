from fastapi import APIRouter, HTTPException, Header, BackgroundTasks, Query, Depends
from typing import Optional, List
import json
from app.schemas.question_generation import (
    QuestionGenerationRequest,
    QuestionGeneration,
    QuestionGenerationSuccessResponse,
    QuestionGenerationErrorResponse,
    BatchJobStartResponse,
    BatchJobErrorResponse,
    ErrorDetail
)
from app.services.question_generation_service import QuestionGenerationService
from app.tasks.question_generation_task import QuestionGenerationTask
from app.utils.dependencies import get_current_user

from app.db.generate import get_generation_config, update_project_status, update_project_generation_config

router = APIRouter()

@router.post(
    "/batch",
    response_model=List[QuestionGenerationSuccessResponse | QuestionGenerationErrorResponse],
    summary="ë°°ì¹˜ ë¬¸í•­ ìƒì„± (ë™ê¸°)",
    description="ì—¬ëŸ¬ ë¬¸í•­ ìƒì„± ìš”ì²­ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ê²°ê³¼ë¥¼ ì¦‰ì‹œ ë°˜í™˜)",
    tags=["ë¬¸í•­ ìƒì„±"]
)
async def generate_questions_batch(
    requests: List[QuestionGeneration],
    provider: Optional[str] = Query(None, description="LLM ì œê³µì", example="gemini"),
    current_user_id: str = Depends(get_current_user)
):
    """
    ë°°ì¹˜ ë¬¸í•­ ìƒì„± API (ë™ê¸° ì²˜ë¦¬)
    
    ì—¬ëŸ¬ ë¬¸í•­ ìƒì„± ìš”ì²­ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - ìµœëŒ€ 10ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬ ê°€ëŠ¥ (10ëª…ì˜ ì‚¬ìš©ì ë˜ëŠ” 10ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ë¬¸í•­ ìƒì„± ìš”ì²­)
    - ê° ìš”ì²­ì€ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤
    - ê° ìš”ì²­ ë‚´ì—ì„œ 10ë¬¸í•­ì”© ë°°ì¹˜ë¡œ ë‚˜ë‰˜ì–´ ì²˜ë¦¬ë©ë‹ˆë‹¤ (ì˜ˆ: 30ë¬¸í•­ ìš”ì²­ â†’ 3ê°œ ë°°ì¹˜)
    - ê° ë°°ì¹˜ë§ˆë‹¤ ë‹¤ë¥¸ API í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬ë©ë‹ˆë‹¤
    - ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
    """
    # TODO: í† í° ê²€ì¦ ë¡œì§ ì¶”ê°€
    
    if len(requests) > 10:
        raise HTTPException(
            status_code=400,
            detail="ë°°ì¹˜ ìš”ì²­ì€ ìµœëŒ€ 10ê°œê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
    # QuestionGeneration ê°ì²´ì—ì„œ í•„ìš”í•œ í•„ë“œë§Œ ë¹¼ë‚´ê³ , QuestionGenerationRequestì— ë§ì¶° ì¬êµ¬ì„±
    question_generation_requests = []
    generation_configs = get_generation_config(requests[0].project_id)

    # ê·¸ëŒ€ë¡œ ë„˜ê²¨ë„ Pydanticì´ ì•Œì•„ì„œ QuestionGenerationRequestì— ë§ëŠ” í•„ë“œë§Œ ë°›ê³  ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œí•¨
    # ì¶”ê°€ í•„ë“œ í•„ìš”í•˜ë©´ ì§ì ‘ ë„˜ê¸¸ ìˆ˜ ìˆê³ , ëˆ„ë½/ë¶ˆí•„ìš”í•œ í•„ë“œëŠ” ìë™ ì œì™¸ë¨
    for request in requests:
        # dictë¡œ ë§Œë“¤ê³  ì¶”ê°€ í•„ë“œ ìˆìœ¼ë©´ ë¯¸ë¦¬ ë³´ê°•
        obj_dict = request.model_dump()
        # ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€ ì˜ˆì‹œ (ì•„ë˜ ì£¼ì„)
        # obj_dict["some_new_field"] = "default_value"
        obj_dict["config_id"] = generation_configs.get("config_id")
        obj_dict["passage"] = generation_configs.get("passage")
        obj_dict["learning_objective"] = generation_configs.get("learning_objective")
        obj_dict["learning_activity"] = generation_configs.get("learning_activity") or ""
        obj_dict["learning_element"] = generation_configs.get("learning_element") or ""
        obj_dict["semester"] = str(generation_configs.get("semester") or "1")
        # achievementsë¥¼ JSON ë¬¸ìì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
        achievements_raw = generation_configs.get("achievements")
        achievements = json.loads(achievements_raw) if achievements_raw else []
        
        obj_dict["curriculum_info"] = [
            {
                "achievement_code": ach.get("code"),
                "achievement_content": ach.get("description"),
                "evaluation_content": ach.get("evaluation_criteria"),
            }
            for ach in achievements
        ]
        obj_dict["school_level"] = generation_configs.get("school_level") or "ì¤‘í•™êµ"
        obj_dict["grade_level"] = str(generation_configs.get("grade") or "")
        obj_dict["large_unit"] = generation_configs.get("large_unit_name") or ""
        obj_dict["small_unit"] = generation_configs.get("small_unit_name") or ""
        obj_dict["generation_count"] = request.target_count
        obj_dict["study_area"] = generation_configs.get("study_area")
        obj_dict["file_paths"] = ["êµ­ì–´ê³¼_êµê³¼ì„œë¡ _1ê¶Œ ìš”ì•½.md", "êµ­ì–´ê³¼_êµê³¼ì„œë¡ _2ê¶Œ ìš”ì•½ë³¸.md"]
        obj_dict["file_display_names"] = ["êµê³¼ì„œë¡  1ê¶Œ", "êµê³¼ì„œë¡  2ê¶Œ"]


        question_generation_requests.append(QuestionGenerationRequest(**obj_dict))
        print("ğŸŸ£")
        print(question_generation_requests)

    service = QuestionGenerationService()
    results = await service.generate_questions_batch(question_generation_requests, current_user_id, provider)
    
    return results


@router.post(
    "/batch-async",
    response_model=BatchJobStartResponse | BatchJobErrorResponse,
    summary="ë°°ì¹˜ ë¬¸í•­ ìƒì„± (ë¹„ë™ê¸°)",
    description="ì—¬ëŸ¬ ë¬¸í•­ ìƒì„± ìš”ì²­ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ DBì— ì €ì¥ë©ë‹ˆë‹¤.",
    tags=["ë¬¸í•­ ìƒì„±"]
)
async def generate_questions_batch_async(
    background_tasks: BackgroundTasks,
    requests: QuestionGeneration,
    provider: Optional[str] = Query(None, description="LLM ì œê³µì", example="gemini"),
    current_user_id: str = Depends(get_current_user)
):
    """
    ë°°ì¹˜ ë¬¸í•­ ìƒì„± API (ë¹„ë™ê¸° ì²˜ë¦¬)
    
    ì—¬ëŸ¬ ë¬¸í•­ ìƒì„± ìš”ì²­ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    - ìµœëŒ€ 10ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬ ê°€ëŠ¥
    - ì¦‰ì‹œ SUCCESS ì‘ë‹µì„ ë°˜í™˜í•˜ê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
    - ì™„ë£Œë˜ë©´ ìë™ìœ¼ë¡œ DBì— ì €ì¥ë©ë‹ˆë‹¤
    - ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë§Œ FAIL ì‘ë‹µ
    """
    try:
        # ìš”ì²­ ê²€ì¦
        if requests.target_count > 30:
            return BatchJobErrorResponse(
                success=False,
                message="ìš”ì²­ ë¬¸í•­ìˆ˜ëŠ” ìµœëŒ€ 30ê°œê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                error=ErrorDetail(
                    code="VALIDATION_ERROR",
                    message="ìš”ì²­ ë¬¸í•­ìˆ˜ëŠ” ìµœëŒ€ 30ê°œê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                )
            )
        
        # QuestionGeneration ê°ì²´ë¥¼ QuestionGenerationRequestë¡œ ë³€í™˜
        question_generation_requests = []
        ## DBì—ì„œ í”„ë¡œì íŠ¸ ì •ë³´ ì¡°íšŒ
        generation_configs = get_generation_config(requests.project_id)

        
        obj_dict = requests.model_dump()
        obj_dict["config_id"] = generation_configs.get("config_id")
        obj_dict["passage"] = generation_configs.get("passage")
        obj_dict["learning_objective"] = generation_configs.get("learning_objective")
        obj_dict["learning_activity"] = generation_configs.get("learning_activity") or ""
        obj_dict["learning_element"] = generation_configs.get("learning_element") or ""
        obj_dict["semester"] = str(generation_configs.get("semester") or "1")
        
        # achievementsë¥¼ JSON ë¬¸ìì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ íŒŒì‹±
        achievements_raw = generation_configs.get("achievements")
        achievements = json.loads(achievements_raw) if achievements_raw else []
        
        obj_dict["curriculum_info"] = [
            {
                "achievement_code": ach.get("code"),
                "achievement_content": ach.get("description"),
                "evaluation_content": ach.get("evaluation_criteria"),
            }
            for ach in achievements
        ]
        obj_dict["school_level"] = generation_configs.get("school_level") or "ì¤‘í•™êµ"
        obj_dict["grade_level"] = str(generation_configs.get("grade") or "")
        obj_dict["large_unit"] = generation_configs.get("large_unit_name") or ""
        obj_dict["small_unit"] = generation_configs.get("small_unit_name") or ""
        obj_dict["generation_count"] = requests.target_count
        obj_dict["study_area"] = generation_configs.get("study_area")
        obj_dict["file_paths"] = ["êµ­ì–´ê³¼_êµê³¼ì„œë¡ _1ê¶Œ ìš”ì•½.md", "êµ­ì–´ê³¼_êµê³¼ì„œë¡ _2ê¶Œ ìš”ì•½ë³¸.md"]
        obj_dict["file_display_names"] = ["êµê³¼ì„œë¡  1ê¶Œ", "êµê³¼ì„œë¡  2ê¶Œ"]

        question_generation_requests.append(QuestionGenerationRequest(**obj_dict))

        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ë“±ë¡
        task = QuestionGenerationTask()
        background_tasks.add_task(
            task.generate_batch_async,
            requests=question_generation_requests,
            user_id=current_user_id,
            provider=provider
        )
        
        ## âŒ›í”„ë¡œì íŠ¸ ìƒíƒœ ìƒì„±ì¤‘ìœ¼ë¡œ ë³€ê²½
        update_project_status(requests.project_id, "GENERATING")

        use_ai_model = 1
        ## ğŸ“¢ìƒì„± ì„¤ì • ë°ì´í„° ì—…ë°ì´íŠ¸
        update_project_generation_config(
            requests.project_id,
            requests.target_count if hasattr(requests, "target_count") and requests.target_count is not None else None,
            requests.stem_directive if hasattr(requests, "stem_directive") and requests.stem_directive is not None else None,
            requests.additional_prompt if hasattr(requests, "additional_prompt") and requests.additional_prompt is not None else None,
            use_ai_model
        )

        print("ğŸŸ£")
        # ì¦‰ì‹œ SUCCESS ì‘ë‹µ ë°˜í™˜
        return BatchJobStartResponse(
            success=True,
            message="ë°°ì¹˜ ë¬¸í•­ ìƒì„±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œ í›„ DBì— ìë™ ì €ì¥ë©ë‹ˆë‹¤.",
            batch_count = (requests.target_count // 10) + (1 if requests.target_count % 10 else 0)
        )
        
    except Exception as e:
        # ì˜ˆì™¸ ë°œìƒ ì‹œ FAIL ì‘ë‹µ
        import traceback
        traceback.print_exc()
        
        return BatchJobErrorResponse(
            success=False,
            message="ë°°ì¹˜ ì‘ì—… ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            error=ErrorDetail(
                code="INTERNAL_ERROR",
                message=str(e),
                details=traceback.format_exc()
            )
        )



@router.post(
    "",
    response_model=QuestionGenerationSuccessResponse | QuestionGenerationErrorResponse,
    summary="ë¬¸í•­ ìƒì„±",
    description="LLM APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸í•­ì„ ìƒì„±í•©ë‹ˆë‹¤.",
    tags=["ë¬¸í•­ ìƒì„±"]
)
async def generate_questions(
    request: QuestionGenerationRequest,
    background_tasks: BackgroundTasks,
    token: Optional[str] = Header(None, alias="token", description="ì¸ì¦ í† í°"),
    provider: Optional[str] = Query(None, description="LLM ì œê³µì (gemini, openai)", example="gemini"),
    async_mode: bool = Query(False, description="ë¹„ë™ê¸° ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€"),
    current_user_id: str = Depends(get_current_user)
):
    """
    ë¬¸í•­ ìƒì„± API
    
    - **passage**: ì›ë³¸ ì§€ë¬¸ í…ìŠ¤íŠ¸
    - **learning_objective**: í•™ìŠµëª©í‘œ
    - **curriculum_info**: êµìœ¡ê³¼ì • ì •ë³´
    - **generation_count**: ìƒì„±í•  ë¬¸í•­ ìˆ˜ (1-50)
    
    ë¹„ë™ê¸° ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    """
    # TODO: í† í° ê²€ì¦ ë¡œì§ ì¶”ê°€
    
    service = QuestionGenerationService()
    
    if async_mode:
        # ë¹„ë™ê¸° ëª¨ë“œ (BackgroundTasks ì‚¬ìš©)
        task = QuestionGenerationTask()
        background_tasks.add_task(
            task.generate_async,
            request=request,
            user_id=current_user_id,
            provider=provider
        )
        
        # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (ì‘ì—…ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰)
        return QuestionGenerationSuccessResponse(
            success=True,
            total_questions=0,
            questions=[],
            message="ë¬¸í•­ ìƒì„±ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤."
        )
    else:
        # ë™ê¸° ëª¨ë“œ
        result = await service.generate_questions(request, current_user_id, provider)
        return result


@router.get(
    "/providers",
    summary="ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì ì¡°íšŒ",
    description="ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
    tags=["ë¬¸í•­ ìƒì„±"]
)
async def get_available_providers():
    """ì‚¬ìš© ê°€ëŠ¥í•œ LLM ì œê³µì ëª©ë¡ ë°˜í™˜"""
    from app.clients.factory import LLMClientFactory
    
    providers = LLMClientFactory.get_available_providers()
    
    return {
        "providers": providers,
        "default": "gemini"
    }

